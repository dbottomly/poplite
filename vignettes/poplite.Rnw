\documentclass[10pt]{article}
\usepackage[margin=1.0in]{geometry}
\usepackage[utf8]{inputenc}
\usepackage[parfill]{parskip}
\SweaveOpts{keep.source=TRUE} 

\title{poplite vignette}
\author{Daniel Bottomly}
%\VignetteIndexEntry{poplite}
\begin{document}

\maketitle

\section{Introduction}

Prior to utilizing a given database in a research context, it has to be designed, scripts written to format existing data to fit into the tables, and the data has to be loaded.
The loading can be as simple as just inserting data into a given table or in addition it may need to respect columns from other tables.  The \texttt{poplite} package was developed
originally to simplify the process of population and management of SQLite databases using R.  It provides a schema object and corresponding methods which allows a user to easily
understand the database structure as well as extend or modify it.  The database can be populated using this schema and the user can specify both raw data and a transformational function
to apply prior to loading.  This functionality facilitates loading of large, non-\texttt{data.frame} type objects as is demonstrated in the 'Advanced Usage' section.  It has since also incorportated
and extended functionality from the \texttt{dplyr} package to provide a convienient query interface using \texttt{dplyr}'s verbs.  Notably, cross table queries can be carried out automatically using
the specified schema object.

\section{Basic Usage}

We will start by working through a simple example that illustrates how to use \texttt{poplite} for many common database tasks.  Our example is a set of 3 \texttt{data.frames} which consists of
randomly generated data which is meant to resemble data collected on patients in a clinical research setting.  We first load the package and the example data, going through each \texttt{data.frame}
in turn.

<<eval=TRUE, echo=TRUE>>=

library(poplite)
data(clinical)

ls()
@

The clinical \texttt{data.frame} contains information on a group of patients including sex, age, disease status as well as other variables/covariates.

<<eval=TRUE, echo=TRUE>>=

head(clinical)

@

The samples \texttt{data.frame} records whether a given patient, keyed by sample\_id was observed in one of several 'waves' and whether they contributed a DNA sample.

<<eval=TRUE, echo=TRUE>>=

head(samples)

@

The dna \texttt{data.frame} provides some information (concentration in nanograms/microliter) on the DNA specimen collected from a given patient during a given wave. 

<<eval=TRUE, echo=TRUE>>=

head(dna)

@

As these data are already in table form, loading them should be relatively straightforward.  The first step is the creation of a schema object of class \texttt{TableSchemaList} whose
name may give the user some indication about its internal structure.  For \texttt{data.frames} a convience function (\texttt{makeSchemaFromData}) is provided which does some basic checks
and creates an appropriate table based on the column names and inferred types.

<<eval=TRUE, echo=TRUE>>=

sample.tracking <- makeSchemaFromData(clinical, "clinical")

sample.tbsl <- makeSchemaFromData(samples, "samples")

sample.tracking <- append(sample.tracking,  sample.tbsl)

try(dna.tbsl <- makeSchemaFromData(dna, "dna"))

@

The error caused by attempting to create a schema object from dna, is due to the formatting of the column name of 'ng.ul' which is a valid R name, but not a valid SQLite name.  A convienient way to
fix this is to use the \texttt{correct.df.names} function as below.  Note that this modified \texttt{data.frame} will be the one that has to be provided to the \texttt{populate} method.

<<eval=TRUE, echo=TRUE>>=

new.dna <- correct.df.names(dna)
dna.tbsl <- makeSchemaFromData(new.dna, "dna")

sample.tracking <- append(sample.tracking, dna.tbsl)

@

At this point, the database can be created and populated using the schema defined in 'sample.tracking' and the data present in the respective \texttt{data.frames}.  However, this requires anyone
who wants to query across the tables be able to determine the relationships between the tables.  In some cases this can be determined by column names alone, in other cases it may not be so clear.  The \texttt{poplite}
package allows the specification of relationships between tables using the R formula syntax.  This functionality is probably best illustrated by example.

The 'clinical' table is the starting point of this database as both the 'samples' and 'dna' tables refer back to its.  In the case of both the 'samples' and 'dna' tables, the 'clinical' table can be refered to using the 'sample\_id' column.
This type of relationship can be created by the following:

<<eval=TRUE, echo=TRUE>>=

relationship(sample.tracking, from="clinical", to="samples") <- sample_id~sample_id
relationship(sample.tracking, from="clinical", to="dna") <-sample_id~sample_id

@

In addition, the 'dna' table can be referred to by the 'samples' table using a combination of 'sample\_id' and 'wave' and vice versa.  Instead of directly cross referencing these columns as we did for 'sample\_id', we specify that we want to use the 'primary key'
of 'samples' in 'dna' as opposed to the combination of 'sample\_id' and 'wave' (though 'sample\_id' will still be kept as it links to the 'clinical' table).  Where the primary key is a column of integer values that uniquely identifies each row and by default it was added
automatically by \texttt{makeSchemaFromData}.  We can specify this in the following manner:

<<eval=TRUE, echo=TRUE>>=

relationship(sample.tracking, from="samples", to="dna") <- .~sample_id+wave

@

Where '.' is a shortcut that indicates that the primary key for the table should be used.  Now that our schema is complete, we are now ready to populate our database.  First, we create a \texttt{Database} object which simply contains both the schema as well as
the file path to where the database resides.  We then call the \texttt{populate} method and provide it with our named \texttt{data.frames}.  At this point it is important to note that by default specifying a relationship between two tables in this manner will result in the 'to'
table being limited to only those values in common between the two tables.  For example specifying the sample\_id+wave relationship between 'samples' and 'dna' will result in the 'dna' table being limited to only those with DNA specimens that have sample IDs and wave values
in the 'samples' table.  The easiest way to address this issue is to directly specify the relationship columns as oppose to referencing the primary keys of a given table.

<<eval=TRUE, echo=TRUE>>=

sample.tracking.db <- Database(sample.tracking, tempfile())
populate(sample.tracking.db, dna=new.dna, samples=samples, clinical=clinical)

@

\subsection{Querying}

As mentioned in the introduction, the query interface utilizes the approach of the \texttt{dplyr} package, whereby a small set of verbs are used to perform common queries.  In addition to utilizing the single table verbs defined in \texttt{dplyr}, \texttt{poplite}
defines multi-table versions of the \texttt{select} and \texttt{filter} verbs.  The \texttt{select} verb allows the user to select columns from a table-like object, in this case an SQLite database. As the \texttt{poplite} version of \texttt{select} and \texttt{filter} can be used for any of the
tables in the defined schema, the most important requirement is for the user to make sure the column(s) are unambigous in terms of the tables.  This can be done in several ways:

(1) Only for the \texttt{select} statement, the \texttt{.tables} argument allows selecting all or part of the columns of a given table(s).  If multiple tables are provided, then they are first joined (an 'inner join' in SQL terminology) using the specified relationships in the schema.  This provides a convienent
way to retrieve a combined version of the data in the database.

<<eval=TRUE, echo=TRUE>>=

select(sample.tracking.db, .tables="dna")

select(sample.tracking.db, sample_id:lab_id, .tables="dna")

select(sample.tracking.db, .tables=c("clinical","dna"))

@

(2) If a column or set of columns uniquely identifies a table, then no further information is needed to execute the query.

<<eval=TRUE, echo=TRUE>>=

select(sample.tracking.db, sample_id:lab_id)

filter(sample.tracking.db, sex == "M" & var_wave_1 > 0)

filter(sample.tracking.db, sample_id == 97 & var_wave_1 > 0)

try(filter(sample.tracking.db, sample_id == 97))

@

(3) A table can be specified in the query using a '.' similar to how it is done in SQL, i.e. tableX.ColumnY.  This only should be done once per statement for \texttt{select} statments, but per variable for filter statements as is shown below.
This restriction reflects how the queries are carried out.  Each grouping of statements statements are applied to the specified or inferred table prior to joining.  Note that for the \texttt{poplite} \texttt{filter} verb cross-table 'OR' statements are currently not
supported.

<<eval=TRUE, echo=TRUE>>=


select(sample.tracking.db, dna.sample_id)

select(sample.tracking.db, dna.sample_id:lab_id)

filter(sample.tracking.db, clinical.sample_id == 97)

filter(sample.tracking.db, clinical.status == 1 & dna.wave==2)

@

The \texttt{poplite} query interface is opt-in meaning that more complex queries can always be carried out directly using the methodology provided in the \texttt{dplyr} package or plain SQL statements after first connecting to the database file using RSQLite.
Below are three approaches of performing the same query:

<<eval=TRUE, echo=TRUE>>=

#poplite + dplyr
wave.1.samp.pop <- filter(select(sample.tracking.db, .tables=c("samples", "dna")), wave == 1)

#dplyr
src.db <- src_sqlite(dbFile(sample.tracking.db), create = F)
samp.tab <- tbl(src.db, "samples")
dna.tab <- tbl(src.db, "dna")
wave.1.samp.dplyr <- inner_join(filter(samp.tab, wave == 1), dna.tab, by=c("samples_ind", "sample_id"))

library(RSQLite)

#RSQLite
samp.db <- dbConnect(SQLite(), dbFile(sample.tracking.db))
wave.1.samp.sql <- dbGetQuery(samp.db, 'SELECT * FROM samples JOIN dna USING (samples_ind, sample_id) WHERE wave == 1')
dbDisconnect(samp.db)

all.equal(as.data.frame(wave.1.samp.pop), wave.1.samp.sql)

all.equal(as.data.frame(wave.1.samp.dplyr), wave.1.samp.sql)

@

\section{Advanced Usage}
One of the the most useful features of \texttt{poplite} is that databases can be created from any R object that can be coerced to a \texttt{data.frame} and they can be populated iteratively.  Our example here involves the parsing and loading of a
variant call format (VCF) file (REFERENCE).  This type of file was devised to encode DNA variations from a reference genome for a given set of samples.  In addition, it can also provide numerical summaries on the confidence that the variant exists
as well as other summary stats and annotations.  For more details, see the following specifications:(REFERENCE). As parsing is already provided by the \texttt{VariantAnnotation} package in Bioconductor (REFERNCE), we will focus on the population of a database
using this data.  We will use the example dataset from the \texttt{VariantAnnotation} package and read it into memory as a \texttt{VCF} object as shown in the vignette.

<<eval=TRUE, echo=FALSE>>=

library(VariantAnnotation)
fl <- system.file("extdata", "chr22.vcf.gz", package="VariantAnnotation")
vcf <- readVcf(fl, "hg19")
@

The first table we will create is a representation of the chromosome, location and reference positions where at least one variant was observed.  To do this we will create a function that takes a \texttt{VCF} object as input and returns a \texttt{data.frame}.
This function and a subset of the \texttt{VCF} object is passed to the \texttt{makeSchemaFromFunction} helper function.  What this helper function does is execute the desired function on the provided \texttt{VCF} object, determine the table structure
from the returned \texttt{data.frame} and package the results in a \texttt{TableSchemaList} object.  It is important that the name(s) for the input objects match between the provided function, \texttt{makeSchemaFromFunction} and ultimately \texttt{populate}. 

<<eval=TRUE, echo=TRUE>>=

populate.ref.table <- function(vcf.obj)
{
    ref.dta <- cbind(
                    seqnames=as.character(seqnames(vcf.obj)),
                    as.data.frame(ranges(vcf.obj))[,c("start", "end")],
                    ref=as.character(ref(vcf.obj)),
                    stringsAsFactors=FALSE
                    )
    return(ref.dta)
}

vcf.sc <- makeSchemaFromFunction(populate.ref.table, "reference", vcf.obj=vcf[1:5])

@

Each variant position in our 'reference' table can have multiple alternatives (termed alleles) which were determined by the genotyping program which generated the VCF file.  The 'alleles' table can be formed as follows:

<<eval=TRUE, echo=TRUE>>=

populate.allele.table <- function(vcf.obj)
{
    exp.obj <- expand(vcf.obj)
    ref.dta <- cbind(
                    seqnames=as.character(seqnames(exp.obj)),
                    as.data.frame(ranges(exp.obj))[,c("start", "end")],
                    ref=as.character(ref(exp.obj)),
                    alt=as.character(alt(exp.obj)),
                    stringsAsFactors=FALSE
                    )
    return(ref.dta)
}

allele.sc <- makeSchemaFromFunction(populate.allele.table, "alleles", vcf.obj=vcf[1:5])

vcf.sc <- poplite::append(vcf.sc, allele.sc)

@

Finally we can form a table that records the number of alternative alleles for each sample.  Implementation Note: the 'allele\_count' column is very simple due to fact that this example dataset
only contains one alternative allele for each variant.  Multi-alleleic cases would have to be dealt with differently.

<<eval=TRUE, echo=TRUE>>=

populate.samp.alt.table <- function(vcf.obj)
{
    temp.vrange <- as(vcf.obj, "VRanges")
    
    ret.dta <- cbind(
                        seqnames=as.character(seqnames(temp.vrange)),
                        as.data.frame(ranges(temp.vrange))[,c("start", "end")],
                        ref=ref(temp.vrange),
                        alt=alt(temp.vrange),
                        sample=as.character(sampleNames(temp.vrange)),
                        allele_count=sapply(strsplit(temp.vrange$GT, "\\|"),
                                function(x) sum(as.integer(x), na.rm=T)),
                        stringsAsFactors=F
                        )
    
    return(ret.dta[ret.dta$allele_count > 0,])
}

geno.all.sc <- makeSchemaFromFunction(populate.samp.alt.table, "sample_alleles", vcf.obj=vcf[1:5])

vcf.sc <- poplite::append(vcf.sc, geno.all.sc)

@

Our relationships can be specified as before.  One wrinkle here is that there is a dependence in the table structures that is more complicated than the sample tracking tables in the 'Basic Usage' section above.  The first
relationship statement below will create a final 'alleles' table with the primary key of 'reference' and the 'alt' column.  As 'sample\_allleles' contains the full column structure of 'alleles' plus the 'sample' and 'allele\_count' columns
it has to be first joined with reference to retrieve its primary key, then joined with the new 'alleles' table to get 'alleles' primary key with the final table resembling: 'alt\_ind', 'sample' and 'allele\_count'.  Just as '.' on the left hand
side indicates the primary key of the 'from' table the '.reference' variable indicates the primary key of the reference table.

<<eval=TRUE, echo=TRUE>>=

relationship(vcf.sc, from="reference", to="alleles") <- .~seqnames+start+end+ref

relationship(vcf.sc, from="reference", to="sample_alleles") <- .~seqnames+start+end+ref

relationship(vcf.sc, from="alleles", to="sample_alleles") <- .~.reference+alt

@

Now that our schema is complete, we can populate our three tables in the database.  In this case, we can populate the entire database with one statement, however for demonstration purposes
we will divide the \texttt{VCF} object into several pieces and populate them one at a time to simulate reading from a large file in chunks or iterating over several files.  Also note that
the 'constraint<-' method is available to provide a mechanism to enforce uniqueness of a subset of columns for a given table which is especially useful if the database is being populated from many files
which may have duplicate data.

<<eval=TRUE, echo=TRUE>>=

vcf.db <- Database(vcf.sc, tempfile())

populate(vcf.db, vcf.obj=vcf[1:1000])

populate(vcf.db, vcf.obj=vcf[1001:2000])

pop.res <- as.data.frame(poplite::select(vcf.db, .tables=tables(vcf.db)))

vrange.tab <- as(vcf[1:2000], "VRanges")

vrange.dta <- data.frame(seqnames=as.character(seqnames(vrange.tab)),
                         start=start(vrange.tab),
                         end=end(vrange.tab),
                         ref=as.character(ref(vrange.tab)),
                         alt=as.character(alt(vrange.tab)),
                         sample=as.character(sampleNames(vrange.tab)),
                         allele_count=sapply(strsplit(vrange.tab$GT, "\\|"),
                                function(x) sum(as.integer(x), na.rm=T)),
                         stringsAsFactors=F)

vrange.dta <- vrange.dta[vrange.dta$allele_count > 0,]

vrange.dta <- vrange.dta[do.call("order", vrange.dta),]

sub.pop.res <- pop.res[,names(vrange.dta)]

sub.pop.res <- sub.pop.res[do.call("order", sub.pop.res),]

all.equal(sub.pop.res, vrange.dta, check.attributes=F)

@


<<eval=TRUE>>=
sessionInfo()
@

\end{document}
